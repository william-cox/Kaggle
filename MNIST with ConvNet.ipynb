{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training and test data files\n",
    "train = pd.read_csv(\"train.csv\").values\n",
    "test  = pd.read_csv(\"test.csv\").values\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Reshape and normalize training data\n",
    "X_train = train[:, 1:].reshape(train.shape[0], 1, 28, 28).astype( 'float32' )\n",
    "X_train = X_train / 255.0\n",
    "\n",
    "# Reshape and normalize test data\n",
    "X_test = test.reshape(test.shape[0], 1, 28, 28).astype( 'float32' )\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# One-hot encode output variable\n",
    "y_train = np_utils.to_categorical(train[:, 0])\n",
    "num_classes = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the ConvNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConvNet architecture\n",
    "\n",
    "1. Convolutional layer with 30 feature maps of size 5×5.\n",
    "2. Pooling layer taking the max over 2*2 patches.\n",
    "3. Convolutional layer with 15 feature maps of size 3×3.\n",
    "4. Pooling layer taking the max over 2*2 patches.\n",
    "5. Dropout layer with a probability of 20%.\n",
    "6. Flatten layer.\n",
    "7. Fully connected layer with 128 neurons and rectifier activation.\n",
    "8. Fully connected layer with 50 neurons and rectifier activation.\n",
    "9. Output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the convnet model\n",
    "def cnn():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(30, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Will\\Anaconda2\\envs\\py35\\lib\\site-packages\\keras\\models.py:851: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "42000/42000 [==============================] - 59s - loss: 0.4873 - acc: 0.8459    \n",
      "Epoch 2/10\n",
      "42000/42000 [==============================] - 59s - loss: 0.1138 - acc: 0.9649    \n",
      "Epoch 3/10\n",
      "42000/42000 [==============================] - 60s - loss: 0.0772 - acc: 0.9762    \n",
      "Epoch 4/10\n",
      "42000/42000 [==============================] - 60s - loss: 0.0627 - acc: 0.9808    \n",
      "Epoch 5/10\n",
      "42000/42000 [==============================] - 56s - loss: 0.0547 - acc: 0.9832    \n",
      "Epoch 6/10\n",
      "42000/42000 [==============================] - 56s - loss: 0.0483 - acc: 0.9850    \n",
      "Epoch 7/10\n",
      "42000/42000 [==============================] - 56s - loss: 0.0405 - acc: 0.9867    \n",
      "Epoch 8/10\n",
      "42000/42000 [==============================] - 56s - loss: 0.0423 - acc: 0.9864    \n",
      "Epoch 9/10\n",
      "42000/42000 [==============================] - 56s - loss: 0.0357 - acc: 0.9893    \n",
      "Epoch 10/10\n",
      "42000/42000 [==============================] - 57s - loss: 0.0319 - acc: 0.9898    \n",
      "Baseline Error: 0.47%\n",
      "27968/28000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = cnn()\n",
    "model.fit(X_train, y_train, nb_epoch=10, batch_size=200, verbose=1)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100)) \n",
    "\n",
    "# Generare predictions\n",
    "yPred = model.predict_classes(X_test)\n",
    "\n",
    "# Generate submission file\n",
    "np.savetxt('submission.csv', np.c_[range(1,len(yPred)+1),yPred], delimiter=',', header = 'ImageId,Label', comments = '', fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
